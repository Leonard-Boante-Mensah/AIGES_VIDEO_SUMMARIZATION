{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leonard-Boante-Mensah/AIGES_VIDEO_SUMMARIZATION/blob/main/AIGES_VIDEO_SUMMARIZATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo5dRg0pE7e0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import h5py\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import argparse\n",
        "import pdb\n",
        "import glob\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import pprint\n",
        "from collections import OrderedDict\n",
        "from prettytable import PrettyTable\n",
        "import json\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERmOHy4nzkqM"
      },
      "source": [
        "**A FUNCTION TO CONVERT VIDEO TO FRAMES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpBc7k8Szguo"
      },
      "outputs": [],
      "source": [
        "def Convert_Video2Frames(video_path, image_path):\n",
        "  capture = cv2.VideoCapture(video_path)\n",
        "  frame_seconds = 0.0831\n",
        "  frameNumber = 1\n",
        "    \n",
        "  while (True):\n",
        "      success, frame = capture.read()\n",
        "      if success:\n",
        "          cv2.imwrite(f'{image_path}img{frameNumber:05}.jpg', frame)\n",
        "      else:\n",
        "          break\n",
        "      frame_seconds += 0.0831\n",
        "      frameNumber += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Fqdpdd0LIm"
      },
      "source": [
        "**A FUNCTION TO PULL THE IMAGES INTO A SINGLE FOLDER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl23iIkTzgra"
      },
      "outputs": [],
      "source": [
        "video_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/'\n",
        "img_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/output/'\n",
        "h5_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/h5_path.h5'\n",
        "# video_dir = Path(video_path).resolve()\n",
        "# video_list = list(video_path.glob('*.mp4'))\n",
        "# print(video_list.sort())\n",
        "# print(video_path)\n",
        "for data in os.listdir(video_path):\n",
        "  dta = data.split('.')[-1]\n",
        "  if dta == 'mp4':\n",
        "    video_dir = f'{video_path}{data}'\n",
        "    img_dir = f\"{img_path}{data.split('.')[0]}/\"\n",
        "    Convert_Video2Frames(video_dir, img_dir)\n",
        "#   video_dir = Path(data).resolve()\n",
        "#    print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJGwl5Xh1o4v"
      },
      "source": [
        "**FUNCTION TO LOAD DATASET FROM GROUND TRUTH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO7DPOyazgmJ"
      },
      "outputs": [],
      "source": [
        "def load_data(dataset):\n",
        "  data = pd.read_excel(dataset, index_col=0)\n",
        "  interest_col = data[['canSpeed']]\n",
        "  interest_col = interest_col.apply(lambda x: abs(x))\n",
        "  percentile_80th = interest_col['canSpeed'].quantile(0.80)\n",
        "  interest_col['canSpeed'] = [1 if y > percentile_80th else 0 for y in interest_col['canSpeed']]\n",
        "  data = interest_col['canSpeed']\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_grRc_O2JPA"
      },
      "source": [
        "**A FUNCTION TO GET THE LABELS OF THE VIDEOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNDL1UPQzgjE"
      },
      "outputs": [],
      "source": [
        "def get_speed_labels(dataset):\n",
        "  data = load_data(dataset)\n",
        "  labels = data.to_numpy()\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-YNZNwG2Z1y"
      },
      "source": [
        "**CREATING OF PERSONAL SUMMARY VIDEOS FROM SPEED THRESHOLD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd3-TgHJzggK"
      },
      "outputs": [],
      "source": [
        "def loadVideoSummary(excel_path, frame_path, vid_path):\n",
        "  # Loading the excel file into the pandaframe\n",
        "  data = pd.read_excel(excel_path, index_col=0)\n",
        "  interest_col = data[['canSpeed']]\n",
        "  interest_col = interest_col.apply(lambda x: abs(x))\n",
        "    \n",
        "  # Change threshold values to 1 and 0\n",
        "  percentile_80th = interest_col['canSpeed'].quantile(0.8)\n",
        "  interest_col['canSpeed'] = [1 if y > percentile_80th else 0 for y in interest_col['canSpeed']]\n",
        "  selected_columns = interest_col.loc[interest_col['canSpeed'] == 1]\n",
        "  index_list = selected_columns.index.tolist()\n",
        "  labels = [x[-12:] for x in index_list]\n",
        "  labels.sort()\n",
        "    \n",
        "  # Load the selected images to the summarized video directory\n",
        "  for img in labels:\n",
        "      r_path = f'{frame_path}{img}'\n",
        "      image = cv2.imread(r_path)\n",
        "      cv2.imwrite(f'{vid_path}{img}', image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORKING WITH THE GROUND TRUTH TABLE"
      ],
      "metadata": {
        "id": "9HLBZX12cxho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading of the raw excel file in a dataframe\n",
        "dataset = pd.read_excel('/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/Annotation_dataset.xlsx')\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "oBEtiYG2cxVQ",
        "outputId": "8e649513-53bd-4fbf-b737-045b30966cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8d3c21db-55a8-420c-9a79-19b5093aba89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cameraRight</th>\n",
              "      <th>cameraFront</th>\n",
              "      <th>cameraRear</th>\n",
              "      <th>cameraLeft</th>\n",
              "      <th>here</th>\n",
              "      <th>tomtom</th>\n",
              "      <th>gpsLatitude</th>\n",
              "      <th>gpsLongitude</th>\n",
              "      <th>gpsAltitude</th>\n",
              "      <th>gpsPrecision</th>\n",
              "      <th>hereMmLatitude</th>\n",
              "      <th>hereMmLongitude</th>\n",
              "      <th>hereSpeedLimit</th>\n",
              "      <th>hereSpeedLimit_2</th>\n",
              "      <th>hereFreeFlowSpeed</th>\n",
              "      <th>hereSignal</th>\n",
              "      <th>hereYield</th>\n",
              "      <th>herePedestrian</th>\n",
              "      <th>hereIntersection</th>\n",
              "      <th>hereMmIntersection</th>\n",
              "      <th>hereSegmentExitHeading</th>\n",
              "      <th>hereSegmentEntryHeading</th>\n",
              "      <th>hereSegmentOthersHeading</th>\n",
              "      <th>hereCurvature</th>\n",
              "      <th>hereCurrentHeading</th>\n",
              "      <th>here1mHeading</th>\n",
              "      <th>here5mHeading</th>\n",
              "      <th>here10mHeading</th>\n",
              "      <th>here20mHeading</th>\n",
              "      <th>here50mHeading</th>\n",
              "      <th>hereTurnNumber</th>\n",
              "      <th>canSteering</th>\n",
              "      <th>canSpeed</th>\n",
              "      <th>chapter</th>\n",
              "      <th>abs_curv</th>\n",
              "      <th>abs_steer</th>\n",
              "      <th>norm_steer</th>\n",
              "      <th>norm_curv</th>\n",
              "      <th>norm_speed</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Appenzell/go_pro_1/image/4/img00001.jpg</td>\n",
              "      <td>Appenzell/go_pro_4/image/4/img00001.jpg</td>\n",
              "      <td>Appenzell/go_pro_5/image/4/img00001.jpg</td>\n",
              "      <td>Appenzell/go_pro_8/image/4/img00001.jpg</td>\n",
              "      <td>Appenzell/here/image/4/img00001.jpg</td>\n",
              "      <td>Appenzell/tomtom/image/4/img00001.jpg</td>\n",
              "      <td>47.328652</td>\n",
              "      <td>8.795806</td>\n",
              "      <td>591.413975</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.328661</td>\n",
              "      <td>8.795782</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.979509</td>\n",
              "      <td>13.823462</td>\n",
              "      <td>28.753016</td>\n",
              "      <td>110.246236</td>\n",
              "      <td>314.526</td>\n",
              "      <td>0.004646</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>151.246924</td>\n",
              "      <td>151.246926</td>\n",
              "      <td>151.246929</td>\n",
              "      <td>123.652396</td>\n",
              "      <td>157.135211</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.918944</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Appenzell/go_pro_1/image/4/img00002.jpg</td>\n",
              "      <td>Appenzell/go_pro_4/image/4/img00002.jpg</td>\n",
              "      <td>Appenzell/go_pro_5/image/4/img00002.jpg</td>\n",
              "      <td>Appenzell/go_pro_8/image/4/img00002.jpg</td>\n",
              "      <td>Appenzell/here/image/4/img00002.jpg</td>\n",
              "      <td>Appenzell/tomtom/image/4/img00002.jpg</td>\n",
              "      <td>47.328653</td>\n",
              "      <td>8.795807</td>\n",
              "      <td>591.407357</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.328662</td>\n",
              "      <td>8.795783</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.849176</td>\n",
              "      <td>13.689723</td>\n",
              "      <td>28.753016</td>\n",
              "      <td>110.246236</td>\n",
              "      <td>314.526</td>\n",
              "      <td>0.004780</td>\n",
              "      <td>28.753077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-27.831429</td>\n",
              "      <td>5.933524</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.151089</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Appenzell/go_pro_1/image/4/img00003.jpg</td>\n",
              "      <td>Appenzell/go_pro_4/image/4/img00003.jpg</td>\n",
              "      <td>Appenzell/go_pro_5/image/4/img00003.jpg</td>\n",
              "      <td>Appenzell/go_pro_8/image/4/img00003.jpg</td>\n",
              "      <td>Appenzell/here/image/4/img00003.jpg</td>\n",
              "      <td>Appenzell/tomtom/image/4/img00003.jpg</td>\n",
              "      <td>47.328653</td>\n",
              "      <td>8.795807</td>\n",
              "      <td>591.417911</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.328662</td>\n",
              "      <td>8.795783</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.849176</td>\n",
              "      <td>13.689723</td>\n",
              "      <td>28.753016</td>\n",
              "      <td>110.246236</td>\n",
              "      <td>314.526</td>\n",
              "      <td>0.004780</td>\n",
              "      <td>28.753077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-27.831429</td>\n",
              "      <td>5.933524</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.379237</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Appenzell/go_pro_1/image/4/img00004.jpg</td>\n",
              "      <td>Appenzell/go_pro_4/image/4/img00004.jpg</td>\n",
              "      <td>Appenzell/go_pro_5/image/4/img00004.jpg</td>\n",
              "      <td>Appenzell/go_pro_8/image/4/img00004.jpg</td>\n",
              "      <td>Appenzell/here/image/4/img00004.jpg</td>\n",
              "      <td>Appenzell/tomtom/image/4/img00004.jpg</td>\n",
              "      <td>47.328654</td>\n",
              "      <td>8.795808</td>\n",
              "      <td>591.430218</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.328663</td>\n",
              "      <td>8.795783</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.718921</td>\n",
              "      <td>13.555984</td>\n",
              "      <td>28.753016</td>\n",
              "      <td>110.246236</td>\n",
              "      <td>314.526</td>\n",
              "      <td>0.004914</td>\n",
              "      <td>28.753077</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-28.111442</td>\n",
              "      <td>5.978812</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.555985</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Appenzell/go_pro_1/image/4/img00005.jpg</td>\n",
              "      <td>Appenzell/go_pro_4/image/4/img00005.jpg</td>\n",
              "      <td>Appenzell/go_pro_5/image/4/img00005.jpg</td>\n",
              "      <td>Appenzell/go_pro_8/image/4/img00005.jpg</td>\n",
              "      <td>Appenzell/here/image/4/img00005.jpg</td>\n",
              "      <td>Appenzell/tomtom/image/4/img00005.jpg</td>\n",
              "      <td>47.328656</td>\n",
              "      <td>8.795810</td>\n",
              "      <td>591.429304</td>\n",
              "      <td>138.0</td>\n",
              "      <td>47.328665</td>\n",
              "      <td>8.795785</td>\n",
              "      <td>50.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.458649</td>\n",
              "      <td>13.288506</td>\n",
              "      <td>28.753016</td>\n",
              "      <td>110.246236</td>\n",
              "      <td>314.526</td>\n",
              "      <td>0.005181</td>\n",
              "      <td>28.753079</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-28.524311</td>\n",
              "      <td>6.097410</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.684775</td>\n",
              "      <td>138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d3c21db-55a8-420c-9a79-19b5093aba89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d3c21db-55a8-420c-9a79-19b5093aba89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d3c21db-55a8-420c-9a79-19b5093aba89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               cameraRight  ... label\n",
              "0  Appenzell/go_pro_1/image/4/img00001.jpg  ...   NaN\n",
              "1  Appenzell/go_pro_1/image/4/img00002.jpg  ...   NaN\n",
              "2  Appenzell/go_pro_1/image/4/img00003.jpg  ...   NaN\n",
              "3  Appenzell/go_pro_1/image/4/img00004.jpg  ...   NaN\n",
              "4  Appenzell/go_pro_1/image/4/img00005.jpg  ...   NaN\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DATA PREPROCESSING STEPS***"
      ],
      "metadata": {
        "id": "XXfiwSdwjrMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-IPLO17jvkV",
        "outputId": "d107c874-74e1-4433-eb5d-c8f057c788b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['cameraRight', 'cameraFront', 'cameraRear', 'cameraLeft', 'here',\n",
            "       'tomtom', 'gpsLatitude', 'gpsLongitude', 'gpsAltitude', 'gpsPrecision',\n",
            "       'hereMmLatitude', 'hereMmLongitude', 'hereSpeedLimit',\n",
            "       'hereSpeedLimit_2', 'hereFreeFlowSpeed', 'hereSignal', 'hereYield',\n",
            "       'herePedestrian', 'hereIntersection', 'hereMmIntersection',\n",
            "       'hereSegmentExitHeading', 'hereSegmentEntryHeading',\n",
            "       'hereSegmentOthersHeading', 'hereCurvature', 'hereCurrentHeading',\n",
            "       'here1mHeading', 'here5mHeading', 'here10mHeading', 'here20mHeading',\n",
            "       'here50mHeading', 'hereTurnNumber', 'canSteering', 'canSpeed',\n",
            "       'chapter', 'abs_curv', 'abs_steer', 'norm_steer', 'norm_curv',\n",
            "       'norm_speed', 'score', 'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['cameraRight', 'cameraFront','cameraRear', 'cameraLeft', 'here',\n",
        "                'tomtom','gpsLatitude', 'gpsLongitude', \n",
        "                'gpsAltitude', 'gpsPrecision','hereMmLatitude', \n",
        "                'hereMmLongitude', 'hereSpeedLimit',\n",
        "                'hereSpeedLimit_2', 'hereFreeFlowSpeed', 'hereSignal', 'hereYield',\n",
        "                'herePedestrian', 'hereIntersection', 'hereMmIntersection',\n",
        "                'hereSegmentExitHeading', 'hereSegmentEntryHeading',\n",
        "                'hereSegmentOthersHeading', 'hereSegmentOthersHeading', 'hereCurvature', 'hereCurrentHeading',\n",
        "                'here1mHeading', 'here5mHeading', 'here10mHeading', 'here20mHeading',\n",
        "                'here50mHeading', 'hereTurnNumber', 'canSteering', 'chapter', 'abs_curv', \n",
        "                'abs_steer', 'norm_steer', 'norm_curv']\n",
        "\n",
        "# Dropping of columns\n",
        "data = dataset.drop(columns=drop_columns)"
      ],
      "metadata": {
        "id": "2NkVUI4ikbWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iLAn3uW30N-4",
        "outputId": "8fd33721-c048-4434-a823-a8af2ccfce5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6494725c-0861-4f9b-983b-0d1e21fd244b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>canSpeed</th>\n",
              "      <th>norm_speed</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.918944</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.151089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.379237</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.555985</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.684775</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6494725c-0861-4f9b-983b-0d1e21fd244b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6494725c-0861-4f9b-983b-0d1e21fd244b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6494725c-0861-4f9b-983b-0d1e21fd244b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   canSpeed  norm_speed  score  label\n",
              "0  2.918944         NaN    NaN    NaN\n",
              "1  3.151089         NaN    NaN    NaN\n",
              "2  3.379237         NaN    NaN    NaN\n",
              "3  3.555985         NaN    NaN    NaN\n",
              "4  3.684775         NaN    NaN    NaN"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kzd3u2oBwkE6",
        "outputId": "4f4613f4-34f7-428e-da59-6775207ab9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ad979b3e-2ac9-4ef1-8242-81910dcec57e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>canSpeed</th>\n",
              "      <th>norm_speed</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14990.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>12.593547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.963667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.501629</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.198367</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16.346169</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.928110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad979b3e-2ac9-4ef1-8242-81910dcec57e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad979b3e-2ac9-4ef1-8242-81910dcec57e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad979b3e-2ac9-4ef1-8242-81910dcec57e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           canSpeed  norm_speed  score  label\n",
              "count  14990.000000         0.0    0.0    0.0\n",
              "mean      12.593547         NaN    NaN    NaN\n",
              "std        4.963667         NaN    NaN    NaN\n",
              "min        0.000000         NaN    NaN    NaN\n",
              "25%       10.501629         NaN    NaN    NaN\n",
              "50%       13.198367         NaN    NaN    NaN\n",
              "75%       16.346169         NaN    NaN    NaN\n",
              "max       20.928110         NaN    NaN    NaN"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gt_score = data.canSpeed"
      ],
      "metadata": {
        "id": "yGflgHmNzXgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdnL2qgc3eqf"
      },
      "source": [
        "**CREATING SUMMARY VIDEOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I5WbyyByjpjE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzne8dDM26XM"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/output/'\n",
        "w_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/summary_video/'\n",
        "e_file = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/'\n",
        "video_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt6EWk1IzgdI"
      },
      "outputs": [],
      "source": [
        "for data in os.listdir(video_path):\n",
        "  dta = data.split('.')[-1]\n",
        "  if dta == 'xlsx':\n",
        "      excel_file = f\"{e_file}{data}\"\n",
        "      frame_path = f\"{path}{data.split('.')[0]}/\"\n",
        "      video_dir = f\"{w_path}{data.split('.')[0]}/\"\n",
        "      loadVideoSummary(excel_file, frame_path, video_dir)\n",
        "\n",
        "#        video_dir = f'{video_path}{data}'\n",
        "#        img_dir = f\"{img_path}{data.split('.')[0]}/\"\n",
        "#        Convert_Video2Frames(video_dir, img_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z5yt6oH3rbt"
      },
      "source": [
        "**CONVERTING VIDEOS TO KEY FEATURES FOR THE MODEL TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiMA13q63ycg"
      },
      "source": [
        "RESCALING OF THE SIZE OF THE IMAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIcJsMC2zgUJ"
      },
      "outputs": [],
      "source": [
        "class Rescale(object):\n",
        "    \"\"\"Rescale a image to a given size.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If tuple, output is matched to output_size. If int, smaller of image edges is matched to output_size keeping aspect ratio the same.\n",
        "    \"\"\"\n",
        "    def __init__(self, *output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image (PIL.Image) : PIL.Image object to rescale\n",
        "        \"\"\"\n",
        "        new_h, new_w = self.output_size\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        img = image.resize((new_w, new_h), resample=Image.BILINEAR)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f2RXFTn38Ma"
      },
      "source": [
        "GETTING THE FEATURES OF THE GOOGLENET PRETRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2EwOXmY4C4X"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),  # HWC->CHW [0,255]->[0.0,1.0]\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# googlenet preparation\n",
        "net = models.googlenet(pretrained=True)\n",
        "\n",
        "\n",
        "# we only want features with no grads\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "net.to(device) # to GPU or CPU\n",
        "fea_net = nn.Sequential(*list(net.children())[:-2]) # pool5 feature\n",
        "fea_net.eval() # eval mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cps = []\n",
        "x, y = 0, 100\n",
        "while y < 14991:\n",
        "    cps.append((x, y))\n",
        "    x = y + 1\n",
        "    y = y + 100\n",
        "\n",
        "x, y = 14901, 14990\n",
        "cps.append((x, y))\n",
        "\n",
        "weight = np.ones(149)\n",
        "weight = weight * 100\n",
        "new_weight = np.append(weight, 90)"
      ],
      "metadata": {
        "id": "jbA-CUYu6KQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def knapsack(v, w, max_weight):\n",
        "    rows = len(v) + 1\n",
        "    cols = max_weight + 1\n",
        "\n",
        "    # adding dummy values as later on we consider these values as indexed from 1 for convinence\n",
        "    \n",
        "    v = np.r_[[0], v]\n",
        "    w = np.r_[[0], w]\n",
        "\n",
        "    # row : values , #col : weights\n",
        "    dp_array = [[0 for i in range(cols)] for j in range(rows)]\n",
        "\n",
        "    # 0th row and 0th column have value 0\n",
        "\n",
        "    # values\n",
        "    for i in range(1, rows):\n",
        "        # weights\n",
        "        for j in range(1, cols):\n",
        "            # if this weight exceeds max_weight at that point\n",
        "            if j - w[i] < 0:\n",
        "                dp_array[i][j] = dp_array[i - 1][j]\n",
        "\n",
        "            # max of -> last ele taken | this ele taken + max of previous values possible\n",
        "            else:\n",
        "                dp_array[i][j] = max(dp_array[i - 1][j], v[i] + dp_array[i - 1][j - w[i]])\n",
        "\n",
        "    # return dp_array[rows][cols]  : will have the max value possible for given wieghts\n",
        "\n",
        "    chosen = []\n",
        "    i = rows - 1\n",
        "    j = cols - 1\n",
        "\n",
        "    # Get the items to be picked\n",
        "    while i > 0 and j > 0:\n",
        "\n",
        "        # ith element is added\n",
        "        if dp_array[i][j] != dp_array[i - 1][j]:\n",
        "            # add the value\n",
        "            chosen.append(i-1)\n",
        "            # decrease the weight possible (j)\n",
        "            j = j - w[i]\n",
        "            # go to previous row\n",
        "            i = i - 1\n",
        "\n",
        "        else:\n",
        "            i = i - 1\n",
        "\n",
        "    return dp_array[rows - 1][cols - 1], chosen"
      ],
      "metadata": {
        "id": "Sv37iNdCBcEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gI1ZPgL4PpA"
      },
      "source": [
        "**CREATING THE FEATURES AND LABELS TO FEED THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVEuuUmL4c5f"
      },
      "outputs": [],
      "source": [
        "def videoTwofeatures(video_path, cps, gt_score):\n",
        "\n",
        "    # for feature and label\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    index = video_path.split('.')[0].split('/')[-1]\n",
        "    tqdm.write('Processing video '+index)\n",
        "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    ratio = round(length / 1499)  \n",
        "\n",
        "    # Handle the Labels\n",
        "    cps = cps\n",
        "    weight = list(new_weight)\n",
        "    weight = [int(w) for w in weight]\n",
        "    gtscore = np.ravel(gt_score.transpose())\n",
        "    n_frame = 14990\n",
        "    value = np.array([gtscore[cp[0]:(cp[1]+1)].mean() for cp in cps])\n",
        "    _, selected = knapsack(value, weight, int(0.30*length))\n",
        "    selected = selected[::-1]\n",
        "\n",
        "    key_shots = np.zeros(shape=(n_frame, ))\n",
        "    key_frames = np.zeros(shape=(n_frame, ))\n",
        "\n",
        "    for i in selected:\n",
        "        key_shots[cps[i][0]:(cps[i][1]+1)] = 1\n",
        "        max_idx = np.where(gtscore[cps[i][0]:(cps[i][1]+1)] == np.max(gtscore[cps[i][0]:(cps[i][1]+1)]))\n",
        "        max_idx = max_idx[0]\n",
        "        key_frames_slice = key_frames[cps[i][0]:(cps[i][1]+1)]\n",
        "        key_frames_slice[max_idx] = 1\n",
        "        \n",
        "    # EXTRACT FEATURES\n",
        "    feature = []\n",
        "    label = []\n",
        "    i = 0\n",
        "    success, frame = video.read()\n",
        "    while success:\n",
        "        if (i+1) % ratio == 0:\n",
        "            frame_RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame_RGB_PIL = Image.fromarray(frame_RGB)\n",
        "            frame_RGB_PIL_transform = transform(frame_RGB_PIL).to(device).view(1,3,224,224)\n",
        "            fea_out = fea_net(frame_RGB_PIL_transform).permute(0,3,2,1).contiguous().view(1024).detach().to(\"cpu\")\n",
        "            feature.append(fea_out)\n",
        "            label.append(key_frames[i])\n",
        "        i += 1\n",
        "        success, frame = video.read()\n",
        "        \n",
        "    # FORMING THE DATASET INTO A STACK USING PYTORCH\n",
        "    feature = torch.stack(feature, 0)\n",
        "    feature = feature[:1499]\n",
        "    label = label[:1499]\n",
        "    return feature, label, cps, weight, n_frame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/joined_appenzel.mp4'"
      ],
      "metadata": {
        "id": "sfZBmDCTYCBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature, label, cps, n_frame_per_seg, length = videoTwofeatures(video_path, cps, gt_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JngyyADnSBw4",
        "outputId": "b8af1ffe-84c6-46ce-dd87-bd44a494917f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video joined_appenzel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAKING OF THE DATASET**"
      ],
      "metadata": {
        "id": "O4bKfToDOUAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h5_data = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/train_videos/h5_video.h5'"
      ],
      "metadata": {
        "id": "myWQndOga27p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(h5_data, 'w') as h5_f:\n",
        "    video_data = h5_f.create_group('training_video')\n",
        "    video_data['feature'] = feature.numpy()\n",
        "    video_data['label'] = label\n",
        "    video_data['length'] = length\n",
        "    video_data['change_points'] = cps\n",
        "    video_data['n_frame_per_seg'] = n_frame_per_seg\n",
        "h5_f.close()"
      ],
      "metadata": {
        "id": "Rz6todzLU1SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2tYaEkg5N1q"
      },
      "source": [
        "**BUILDING THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roIJOZoH5Tsw"
      },
      "outputs": [],
      "source": [
        "def build_dataset(video_dir, summary_dir, hd5_path):\n",
        "  video_dir = Path(video_dir).resolve()\n",
        "  video_list = list(video_dir.glob('*.mp4'))\n",
        "  video_list.sort()\n",
        "    \n",
        "  # Creating the HDF5 folder for the dataset\n",
        "  with h5py.File(hd5_path, 'w') as h5_f:\n",
        "      for video_path in tqdm(video_list, desc='Video', ncols=80, leave=False):\n",
        "          videoTwofeatures(video_path, summary_dir, h5_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dH0pzXoC5g3_"
      },
      "outputs": [],
      "source": [
        "build_dataset(video_path, selected_frames, hd5_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qauo-KBg5Z8r"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING THE TRAINING AND TESTING DATASET**"
      ],
      "metadata": {
        "id": "nR3XznjxkQBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING A CLASS FOR THE VIDEO DATASET\n",
        "class VideoData(object):\n",
        "    def __init__(self, data_path):\n",
        "        self.data_file = h5py.File(data_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_file)\n",
        "\n",
        "    def __getitem__(self, train_data):\n",
        "        video = self.data_file['training_video']\n",
        "        feature = video_feature = torch.from_numpy(video[\"feature\"][...]).transpose(1,0).view(1024,-1)\n",
        "        label = torch.from_numpy(video[\"label\"][...]).type(torch.long)\n",
        "        return feature, label"
      ],
      "metadata": {
        "id": "BmWGtyzwka_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADER FUNCTION**"
      ],
      "metadata": {
        "id": "B2dGcyCXmV1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(path, batch_size=5):\n",
        "    # Loading the training dataset\n",
        "    dataset = VideoData(path)\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - len(dataset) // 5, len(dataset) // 5])\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "    return train_loader, test_dataset\n",
        "\n",
        "    # train_loader_list = []\n",
        "    # test_dataset_list = []\n",
        "\n",
        "    # split_times = 5\n",
        "\n",
        "    # for i in range(split_times):\n",
        "    #     train_dataset,test_dataset = torch.utils.data.random_split(dataset, [int(dataset.__len__()*0.8), int(dataset.__len__()*0.2)])\n",
        "\n",
        "    #     # shuffle (bool, optional): set to `True` to have the data reshuffled at every epoch\n",
        "    #     train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "\n",
        "    #     train_loader_list.append(train_loader)\n",
        "    #     test_dataset_list.append(test_dataset)\n",
        "\n",
        "    # return train_loader_list, test_dataset_list, dataset.data_file"
      ],
      "metadata": {
        "id": "2ZZeGHoCka8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATE A CONFIGURATION TO SAVE MODEL SCORES AND PREDICTIONS**"
      ],
      "metadata": {
        "id": "2WCzUyh7qYPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config():\n",
        "  \"\"\"Config class\"\"\"\n",
        "  def __init__(self, **kwargs):\n",
        "      # Path\n",
        "      self.data_path = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/h5_path.h5'\n",
        "      self.save_dir = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/save_dir'\n",
        "      self.score_dir = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/score_dir'\n",
        "      self.log_dir = '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/log_dir'\n",
        "\n",
        "      # Model\n",
        "      self.mode = 'train'\n",
        "      self.gpu = True\n",
        "      self.n_epochs = 5\n",
        "      self.n_class = 2\n",
        "      self.lr = 1e-3\n",
        "      self.momentum = 0.9\n",
        "      self.batch_size = 5\n",
        "\n",
        "      for k, v in kwargs.items():\n",
        "        setattr(self, k, v)\n",
        "\n",
        "  def __repr__(self):\n",
        "    config_str = 'Configurations\\n' + pprint.pformat(self.__dict__)\n",
        "    return config_str"
      ],
      "metadata": {
        "id": "YP3ZuOyPka5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psrhINritFVD",
        "outputId": "9873b3a7-d0aa-42ee-8085-e66e5b0f6cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations\n",
            "{'batch_size': 5,\n",
            " 'data_path': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/h5_path.h5',\n",
            " 'gpu': True,\n",
            " 'log_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/log_dir',\n",
            " 'lr': 0.001,\n",
            " 'mode': 'train',\n",
            " 'momentum': 0.9,\n",
            " 'n_class': 2,\n",
            " 'n_epochs': 5,\n",
            " 'save_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/save_dir',\n",
            " 'score_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/score_dir'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING THE FULLY CONVOLUTIONAL SEMANTIC NETWORK**"
      ],
      "metadata": {
        "id": "sqd7yfoYrmrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7yXNhlOgotCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FCSN(nn.Module):\n",
        "  def __init__(self, n_class=2):\n",
        "    super(FCSN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(OrderedDict([\n",
        "      ('conv1_1', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn1_1', nn.BatchNorm1d(1024)),\n",
        "      ('relu1_1', nn.ReLU(inplace=True)),\n",
        "      ('conv1_2', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn1_2', nn.BatchNorm1d(1024)),\n",
        "      ('relu1_2', nn.ReLU(inplace=True)),\n",
        "      ('pool1', nn.MaxPool1d(2, stride=2, ceil_mode=True))\n",
        "      ])) # 1/2\n",
        "\n",
        "    self.conv2 = nn.Sequential(OrderedDict([\n",
        "      ('conv2_1', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn2_1', nn.BatchNorm1d(1024)),\n",
        "      ('relu2_1', nn.ReLU(inplace=True)),\n",
        "      ('conv2_2', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn2_2', nn.BatchNorm1d(1024)),\n",
        "      ('relu2_2', nn.ReLU(inplace=True)),\n",
        "      ('pool2', nn.MaxPool1d(2, stride=2, ceil_mode=True))\n",
        "      ])) # 1/4\n",
        "\n",
        "    self.conv3 = nn.Sequential(OrderedDict([\n",
        "      ('conv3_1', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn3_1', nn.BatchNorm1d(1024)),\n",
        "      ('relu3_1', nn.ReLU(inplace=True)),\n",
        "      ('conv3_2', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "      ('bn3_2', nn.BatchNorm1d(1024)),\n",
        "      ('relu3_2', nn.ReLU(inplace=True)),\n",
        "      ('conv3_3', nn.Conv1d(1024, 1024, 3, padding=1)),\n",
        "          ('bn3_3', nn.BatchNorm1d(1024)),\n",
        "          ('relu3_3', nn.ReLU(inplace=True)),\n",
        "          ('pool3', nn.MaxPool1d(2, stride=2, ceil_mode=True))\n",
        "          ])) # 1/8\n",
        "\n",
        "    self.conv4 = nn.Sequential(OrderedDict([\n",
        "        ('conv4_1', nn.Conv1d(1024, 2048, 3, padding=1)),\n",
        "        ('bn4_1', nn.BatchNorm1d(2048)),\n",
        "        ('relu4_1', nn.ReLU(inplace=True)),\n",
        "        ('conv4_2', nn.Conv1d(2048, 2048, 3, padding=1)),\n",
        "        ('bn4_2', nn.BatchNorm1d(2048)),\n",
        "        ('relu4_2', nn.ReLU(inplace=True)),\n",
        "        ('conv4_3', nn.Conv1d(2048, 2048, 3, padding=1)),\n",
        "        ('bn4_3', nn.BatchNorm1d(2048)),\n",
        "        ('relu4_3', nn.ReLU(inplace=True)),\n",
        "        ('pool4', nn.MaxPool1d(2, stride=2, ceil_mode=True))\n",
        "        ])) # 1/16\n",
        "\n",
        "    self.conv5 = nn.Sequential(OrderedDict([\n",
        "        ('conv5_1', nn.Conv1d(2048, 2048, 3, padding=1)),\n",
        "        ('bn5_1', nn.BatchNorm1d(2048)),\n",
        "        ('relu5_1', nn.ReLU(inplace=True)),\n",
        "        ('conv5_2', nn.Conv1d(2048, 2048, 3, padding=1)),\n",
        "        ('bn5_2', nn.BatchNorm1d(2048)),\n",
        "        ('relu5_2', nn.ReLU(inplace=True)),\n",
        "        ('conv5_3', nn.Conv1d(2048, 2048, 3, padding=1)),\n",
        "        ('bn5_3', nn.BatchNorm1d(2048)),\n",
        "        ('relu5_3', nn.ReLU(inplace=True)),\n",
        "        ('pool5', nn.MaxPool1d(2, stride=2, ceil_mode=True))\n",
        "        ])) # 1/32\n",
        "\n",
        "    self.conv6 = nn.Sequential(OrderedDict([\n",
        "        ('fc6', nn.Conv1d(2048, 4096, 1)),\n",
        "        ('bn6', nn.BatchNorm1d(4096)),\n",
        "        ('relu6', nn.ReLU(inplace=True)),\n",
        "        ('drop6', nn.Dropout())\n",
        "        ]))\n",
        "   \n",
        "    self.conv7 = nn.Sequential(OrderedDict([\n",
        "        ('fc7', nn.Conv1d(4096, 4096, 1)),\n",
        "        ('bn7', nn.BatchNorm1d(4096)),\n",
        "        ('relu7', nn.ReLU(inplace=True)),\n",
        "        ('drop7', nn.Dropout())\n",
        "        ]))\n",
        "\n",
        "    self.conv8 = nn.Sequential(OrderedDict([\n",
        "        ('fc8', nn.Conv1d(4096, n_class, 1)),\n",
        "        ('bn8', nn.BatchNorm1d(n_class)),\n",
        "        ('relu8', nn.ReLU(inplace=True)),\n",
        "        ]))\n",
        "\n",
        "    self.conv_pool4 = nn.Conv1d(2048, n_class, 1)\n",
        "    self.bn_pool4 = nn.BatchNorm1d(n_class)\n",
        "\n",
        "    self.deconv1 = nn.ConvTranspose1d(n_class, n_class, 4, padding=1, stride=2, bias=False)\n",
        "    self.deconv2 = nn.ConvTranspose1d(n_class, n_class, 16, stride=16, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = x\n",
        "    h = self.conv1(h)\n",
        "    h = self.conv2(h)\n",
        "    h = self.conv3(h)\n",
        "    h = self.conv4(h)\n",
        "    pool4 = h\n",
        "\n",
        "    h = self.conv5(h)\n",
        "    h = self.conv6(h)\n",
        "    h = self.conv7(h)\n",
        "    h = self.conv8(h)\n",
        "\n",
        "    h = self.deconv1(h)\n",
        "    upscore2 = h\n",
        "\n",
        "    h = self.conv_pool4(pool4)\n",
        "    h = self.bn_pool4(h)\n",
        "    score_pool4 = h\n",
        "\n",
        "    h = upscore2 + score_pool4\n",
        "\n",
        "    h = self.deconv2(h)\n",
        "\n",
        "    # h_softmax = self.softmax(h) # [5,2,320]\n",
        "    # mask = h_softmax[:,1,:].view(-1,1,1499) # [5,1,320] use key frame score to be the mask\n",
        "\n",
        "    # h_reconstruct = self.relu_reconstuct1(self.bn_reconstruct1(self.conv_reconstuct1(h))) # [5,1024,320]\n",
        "\n",
        "    # # merge with input features\n",
        "    # h_merge = h_reconstruct + x # [5,1024,1499]\n",
        "    # h_merge_reconstruct = self.relu_reconstuct2(self.bn_reconstruct2(self.conv_reconstuct2(h_merge))) # [5,1024,320]\n",
        "\n",
        "    # return h_merge_reconstruct, mask, h # [5,1024,320], [5,1,320], [5,2,320]\n",
        "\n",
        "    return h"
      ],
      "metadata": {
        "id": "fqkT6fz3n6k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ld7NU1W-pmIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UPSAMPLING OF THE FRAMES IN THE VIDEO**"
      ],
      "metadata": {
        "id": "0Btk9YlX3pFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample(down_arr, N):\n",
        "  up_arr = np.zeros(N)\n",
        "  ratio = N // 1499\n",
        "  l = (N - ratio * 1499) // 2\n",
        "  i = 0\n",
        "  while i < 1499:\n",
        "    up_arr[l:l+ratio] = np.ones(ratio, dtype=int) * down_arr[i]\n",
        "    l += ratio\n",
        "    i += 1\n",
        "  return up_arr"
      ],
      "metadata": {
        "id": "VIVVkRl_3vV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FCSN()\n",
        "data = torch.randn((1, 1024, 1499))\n",
        "print(net(data).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4SBUfZ1pKqg",
        "outputId": "8ff60fa3-7b61-4660-e05b-78593e127a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 1504])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CACULATING PREDICTION SCORE**"
      ],
      "metadata": {
        "id": "WYo2lLJi53Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_keyshots(video_info, pred_score):\n",
        "    N = video_info['length'][()]\n",
        "    cps = video_info['change_points'][()]\n",
        "    weight = video_info['n_frame_per_seg'][()]\n",
        "    pred_score = np.array(pred_score.cpu().data)\n",
        "    pred_score = upsample(pred_score, N)\n",
        "\n",
        "    pred_value = np.array([pred_score[cp[0]:cp[1]].mean() for cp in cps])\n",
        "    _, selected = knapsack(pred_value, weight, int(0.15 * N))\n",
        "    selected = selected[::-1]\n",
        "    key_labels = np.zeros(shape=(N, ))\n",
        "    for i in selected:\n",
        "        key_labels[cps[i][0]:cps[i][1]] = 1\n",
        "    return pred_score.tolist(), selected, key_labels.tolist()\n",
        "  "
      ],
      "metadata": {
        "id": "X2en7-GX3oNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CREATE CLASS FOR TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "vZlUTBweurKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Solver(object):\n",
        "    def __init__(self, config=None, train_loader=None, test_dataset=None):\n",
        "\n",
        "        \"\"\"Class that Builds, Trains FCSN model\"\"\"\n",
        "        self.config = config\n",
        "        self.train_loader = train_loader\n",
        "        self.test_dataset = test_dataset\n",
        "\n",
        "        # model\n",
        "        self.model = FCSN(self.config.n_class)\n",
        "\n",
        "        # optimizer\n",
        "        if self.config.mode == 'train':\n",
        "            self.optimizer = optim.Adam(self.model.parameters())\n",
        "            # self.optimizer = optim.SGD(self.model.parameters(), lr=config.lr, momentum=self.config.momentum)\n",
        "            self.model.train()\n",
        "\n",
        "        if self.config.gpu:\n",
        "            self.model = self.model.cuda()\n",
        "\n",
        "        if not os.path.exists(self.config.score_dir):\n",
        "            os.mkdir(self.config.score_dir)\n",
        "\n",
        "        if not os.path.exists(self.config.save_dir):\n",
        "            os.mkdir(self.config.save_dir)\n",
        "\n",
        "        if not os.path.exists(self.config.log_dir):\n",
        "            os.mkdir(self.config.log_dir)\n",
        "    \n",
        "    @staticmethod\n",
        "    def sum_loss(pred_score, gt_labels, weight=None):\n",
        "        n_batch, n_class, n_frame = pred_score.shape\n",
        "        log_p = torch.log_softmax(pred_score, dim=1).reshape(-1, n_class)\n",
        "        gt_labels = gt_labels.reshape(-1)\n",
        "        criterion = torch.nn.NLLLoss(weight)\n",
        "        loss = criterion(log_p, gt_labels)\n",
        "        return loss\n",
        "\n",
        "    def train(self):\n",
        "        writer = SummaryWriter(log_dir=self.config.log_dir)\n",
        "        t = trange(self.config.n_epochs, desc='Epoch', ncols=80)\n",
        "\n",
        "        for epoch_i in t:\n",
        "            sum_loss_history = []\n",
        "            for batch_i, (feature, label) in enumerate(tqdm(self.train_loader, desc='Batch', ncols=80, leave=False)):\n",
        "                # Hey yah\n",
        "                # [batch_size, 1024, seq_len]\n",
        "                feature.requires_grad_()\n",
        "                # => cuda\n",
        "                if self.config.gpu:\n",
        "                    feature = feature.cuda()\n",
        "                    label = label\n",
        "\n",
        "                # ------- Train --------- #\n",
        "                pred_score = self.model(feature)\n",
        "                label_1 = label.sum() / label.shape[0]\n",
        "                label_0 = label.shape[1] - label_1\n",
        "                weight = torch.tensor([label_1, label_0], dtype=torch.float)\n",
        "\n",
        "                if self.config.gpu:\n",
        "                    weight = weight.cuda()\n",
        "\n",
        "                loss = self.sum_loss(pred_score, label, weight)\n",
        "                loss.backward()\n",
        "\n",
        "                self.optimer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                sum_loss_history.append(loss)\n",
        "                print(sum_loss_history)\n",
        "\n",
        "            mean_loss = torch.stack(sum_loss_history).mean().item()\n",
        "            t.set_postfix(loss=mean_loss)\n",
        "            writer.add_scalar('Loss', mean_loss, epoch_i)\n",
        "\n",
        "            if (epoch_i+1) % 5 == 0:\n",
        "                # Calculating the Epoch\n",
        "                ckpt_path = self.config.save_dir + '/epoch-{}.pkl'.format(epoch_i)\n",
        "                tqdm.write('Save parameters at {}'.format(ckpt_path))\n",
        "                torch.save(self.model.state_dict(), ckpt_path)\n",
        "                self.evaluate(epoch_i)\n",
        "                self.model.train()\n",
        "\n",
        "    def evaluate(self, epoch_i):\n",
        "        self.model.eval()\n",
        "        out_dict = {}\n",
        "        eval_arr = []\n",
        "        table = PrettyTable()\n",
        "        table.title = f'Evaluation Result of Epoch {epoch_i}'\n",
        "        table.field.names = ['ID', 'Precision', 'Recall', 'F-score']\n",
        "        table.float_format = '1.3'\n",
        "\n",
        "        with h5py.File(self.config.data_path) as data_file:\n",
        "            for feature, label, idx in tqdm(self.test_dataset, desc='Evaluate', ncols=80, leave=False):\n",
        "                if self.config.gpu:\n",
        "                    feature = feature.cuda()\n",
        "                    pred_score = self.model(feature.unqueeze(0).squeeze(0))\n",
        "                    pred_score = torch.softmax(pred_score, dim=0)[1]\n",
        "                    video_info = data_file['training_video']\n",
        "                \n",
        "                pred_score, pred_selected, pred_summary = select_keyshots(video_info, pred_score)\n",
        "\n",
        "                out_dict[idx] = {\n",
        "                    'pred_score': pred_score,\n",
        "                    'pred_selected': pred_selected,\n",
        "                    'pred_summary': pred_summary\n",
        "                }\n",
        "\n",
        "        score_save_path = self.config.score_dir + '/epoch-{}.json'.format(epoch_i)\n",
        "        with open(score_save_path, 'w') as f:\n",
        "            tqdm.write('Save score at {}'.format(str(score_save_path)))\n",
        "            json.dump(out_dict, f)\n",
        "        tqdm.write(str(table))"
      ],
      "metadata": {
        "id": "9HbWDju4n6iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_loss(pred_score, gt_labels, weight=None):\n",
        "    n_batch, n_class, n_frame = pred_score.shape\n",
        "    log_p = torch.log_softmax(pred_score, dim=1).reshape(-1, n_class)\n",
        "    gt_labels = gt_labels.reshape(-1)\n",
        "    criterion = torch.nn.NLLLoss(weight)\n",
        "    loss = criterion(log_p, gt_labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "PDIRFf6vMhxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "MVvYE3C_NnHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch_i in t:\n",
        "    sum_loss_history = []\n",
        "    for batch_i, (feature, label) in enumerate(tqdm(train_loader_list, desc='Batch', ncols=80, leave=False)):\n",
        "        feature.requires_grad_()\n",
        "\n",
        "        if config.gpu:\n",
        "            feature = feature.cuda()\n",
        "            label = label.to(device)\n",
        "        pred_score = model(feature)\n",
        "        print(pred_score)\n",
        "        label_1 = label.sum() / label.shape[0]\n",
        "        label_0 = label.shape[1] - label_1\n",
        "        weight = torch.tensor([label_1, label_0], dtype=torch.float)\n",
        "\n",
        "        if config.gpu:\n",
        "            weight = weight.cuda()\n",
        "        print(pred_score.shape)\n",
        "        print(label.shape)\n",
        "\n",
        "        # loss = sum_loss(pred_score, label, weight)\n",
        "        # loss.backward()\n",
        "\n",
        "        # print(loss)\n",
        "\n",
        "        # optimizer.step()\n",
        "        # optimizer.zero_grad()\n",
        "        # sum_loss_history.append(loss)\n",
        "\n",
        "        # n_batch, n_class, f_frame = pred_score.shape\n",
        "        # print(n_class)\n",
        "\n",
        "        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GakDC5ea6Uq5",
        "outputId": "a409c88f-6f74-4a8f-f55f-295cd6429056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0726,  0.0633, -0.1778,  ..., -0.1156,  0.1799, -0.1160],\n",
            "         [ 0.0897, -0.0598,  0.0993,  ..., -0.1700, -0.0044,  0.1303]]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 2, 1504])\n",
            "torch.Size([1, 1499])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0677,  0.0611, -0.1711,  ..., -0.1165,  0.1993, -0.1111],\n",
            "         [ 0.0860, -0.0563,  0.0942,  ..., -0.1746,  0.0195,  0.1305]]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 2, 1504])\n",
            "torch.Size([1, 1499])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0774,  0.0623, -0.1765,  ..., -0.1156,  0.1799, -0.1160],\n",
            "         [ 0.0898, -0.0624,  0.1018,  ..., -0.1700, -0.0044,  0.1303]]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 2, 1504])\n",
            "torch.Size([1, 1499])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0915,  0.0640, -0.1843,  ..., -0.1156,  0.1799, -0.1160],\n",
            "         [ 0.0953, -0.0711,  0.1128,  ..., -0.1700, -0.0044,  0.1303]]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 2, 1504])\n",
            "torch.Size([1, 1499])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0677,  0.0611, -0.1711,  ..., -0.1073,  0.1843, -0.1021],\n",
            "         [ 0.0860, -0.0563,  0.0942,  ..., -0.1609,  0.0189,  0.1202]]],\n",
            "       device='cuda:0', grad_fn=<SqueezeBackward1>)\n",
            "torch.Size([1, 2, 1504])\n",
            "torch.Size([1, 1499])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTING OF THE MODEL**"
      ],
      "metadata": {
        "id": "HdkE20_KypCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = Config()\n",
        "test_config = Config(mode='test')\n",
        "train_loader, test_dataset = get_loader(train_config.data_path, batch_size=train_config.batch_size)\n",
        "solver = Solver(train_config, train_loader, test_dataset)"
      ],
      "metadata": {
        "id": "FaqOHjH-ys7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qptylgxAfzcM",
        "outputId": "04179036-2b39-4726-dccd-8457c1b05e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations\n",
            "{'batch_size': 5,\n",
            " 'data_path': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/h5_path.h5',\n",
            " 'gpu': True,\n",
            " 'log_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/log_dir',\n",
            " 'lr': 0.001,\n",
            " 'mode': 'train',\n",
            " 'momentum': 0.9,\n",
            " 'n_class': 2,\n",
            " 'n_epochs': 5,\n",
            " 'save_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/save_dir',\n",
            " 'score_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/score_dir'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_config = Config(mode='test')"
      ],
      "metadata": {
        "id": "q1p2mJnQn6at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOK_zbF-f7jF",
        "outputId": "0a8f8bf9-fddf-4950-8c50-8d8feaf6822b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations\n",
            "{'batch_size': 5,\n",
            " 'data_path': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/train/h5_path.h5',\n",
            " 'gpu': True,\n",
            " 'log_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/log_dir',\n",
            " 'lr': 0.001,\n",
            " 'mode': 'test',\n",
            " 'momentum': 0.9,\n",
            " 'n_class': 2,\n",
            " 'n_epochs': 5,\n",
            " 'save_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/save_dir',\n",
            " 'score_dir': '/content/drive/MyDrive/Video_summarization_build/video_summarization_aiges/dataset/score_dir'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_dataset = get_loader(train_config.data_path, batch_size=train_config.batch_size)"
      ],
      "metadata": {
        "id": "SdBS3JE2n6YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF0EhhTSf_Kz",
        "outputId": "ecf16df0-ec1c-4733-bafe-746d7ae73fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataset.Subset object at 0x7f1cc355cd90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver = Solver(train_config, train_loader, test_dataset)"
      ],
      "metadata": {
        "id": "U_RrJ1Nzn6VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC4R_89-KjY6"
      },
      "source": [
        "**FUNCTION TO CONVERT VIDEO DATA TO FRAMES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKjDmn25Gt1b"
      },
      "outputs": [],
      "source": [
        "def Convert_Video2Frames(video_path, image_path):\n",
        "  capture = cv2.VideoCapture(video_path)\n",
        "  frame_seconds = 0.0831\n",
        "  frameNumber = 1\n",
        "\n",
        "  while (True):\n",
        "    success, frame = capture.read()\n",
        "    if success:\n",
        "      cv2.imwrite(f'{image_path}img{frameNumber:05}.jpg', frame)\n",
        "    else:\n",
        "      break\n",
        "    frame_seconds += 0.0831\n",
        "    frameNumber += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HZDJZhxwNFv"
      },
      "outputs": [],
      "source": [
        "video_path = 'C:/Users/joepr/Documents/AIGES_CAPSTONE_PROJECT/video_summarization_aiges/dataset/train/train_videos/'\n",
        "img_path = 'C:/Users/joepr/Documents/AIGES_CAPSTONE_PROJECT/video_summarization_aiges/dataset/train/output/'\n",
        "h5_path = 'C:/Users/joepr/Documents/AIGES_CAPSTONE_PROJECT/video_summarization_aiges/dataset/train/h5_path'\n",
        "# video_dir = Path(video_path).resolve()\n",
        "# video_list = list(video_path.glob('*.mp4'))\n",
        "# print(video_list.sort())\n",
        "# print(video_path)\n",
        "for data in os.listdir(video_path):\n",
        "    dta = data.split('.')[-1]\n",
        "    if dta == 'mp4':\n",
        "        video_dir = f'{video_path}{data}'\n",
        "        img_dir = f\"{img_path}{data.split('.')[0]}/\"\n",
        "        Convert_Video2Frames(video_dir, img_dir)\n",
        "#     video_dir = Path(data).resolve()\n",
        "#     print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELI2WB3xMfJR"
      },
      "source": [
        "**FUNCTION TO PREPARE EXCEL DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTaFatCjMpBu"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(data_path):\n",
        "  data = pd.read_excel(data_path, index_col=0)\n",
        "  col = data[['canSpeed']]\n",
        "  col = col.apply(lambda x: abs(x))\n",
        "  max_speed = col['canSpeed'].max()\n",
        "  mean_speed = col['canSpeed'].mean()\n",
        "  col['mean_speed'] = [1 if y > mean_speed else 0 for y in col['canSpeed']]\n",
        "  col['max_speed'] = [1 if y > max_speed else 0 for y in col['canSpeed']]\n",
        "  mean_selected = col[col['mean_speed'] == 1]\n",
        "  max_selected = col[col['max_speed'] == 1]\n",
        "  mean_selected = mean_selected.index.tolist()\n",
        "  max_selected = max_selected.index.tolist()\n",
        "  mean_labels = [row[-12:] for row in mean_selected]\n",
        "  max_labels = [row[-12:] for row in max_selected]\n",
        "  mean_labels.sort()\n",
        "  max_labels.sort()\n",
        "  return mean_labels, max_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-5A_m70U_XU"
      },
      "source": [
        "**WRITE SELECTED FRAMES INTO ANOTHER FOLDER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX7dGDQSVFBG"
      },
      "outputs": [],
      "source": [
        "def selected_frames(path1, path2, sel_images):\n",
        "  for img in sel_images:\n",
        "    path = f'{path1}{img}'\n",
        "    image = cv2.imread(path)\n",
        "    cv2.imwrite('f{path2}{img}', image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "AIGES VIDEO SUMMARIZATION.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vZlUTBweurKp"
      ],
      "mount_file_id": "1JnkKCbU12IdNqO-w5IS4SpTbNpERPjwb",
      "authorship_tag": "ABX9TyMG1/a8bl1IXaCd7ugycacq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}